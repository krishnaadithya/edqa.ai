{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kECQMbBxMNIm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2s6bVw3RMcoM"
      },
      "outputs": [],
      "source": [
        "from pytubefix import YouTube\n",
        "from pytubefix.cli import on_progress\n",
        "from groq import Groq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qplDbnCNMei8"
      },
      "outputs": [],
      "source": [
        "def _timestamp_to_seconds(timestamp: str) -> float:\n",
        "    \"\"\"Convert SRT timestamp to seconds.\"\"\"\n",
        "    if ',' in timestamp:\n",
        "        timestamp = timestamp.replace(',', '.')\n",
        "\n",
        "    parts = timestamp.split(':')\n",
        "    if len(parts) == 3:\n",
        "        hours, minutes, seconds = parts\n",
        "        return float(hours) * 3600 + float(minutes) * 60 + float(seconds)\n",
        "    return 0\n",
        "\n",
        "def _parse_srt_captions(srt_captions: str):\n",
        "    \"\"\"Parse SRT format captions into segments.\"\"\"\n",
        "    segments = []\n",
        "    current_segment = {}\n",
        "\n",
        "    for line in srt_captions.split('\\n'):\n",
        "        line = line.strip()\n",
        "\n",
        "        if line.isdigit():  # Segment number\n",
        "            if current_segment:\n",
        "                segments.append(current_segment)\n",
        "            current_segment = {}\n",
        "        elif '-->' in line:  # Timestamp\n",
        "            start, end = line.split('-->')\n",
        "            current_segment['start'] = _timestamp_to_seconds(start.strip())\n",
        "            current_segment['end'] = _timestamp_to_seconds(end.strip())\n",
        "        elif line:  # Text content\n",
        "            if 'text' in current_segment:\n",
        "                current_segment['text'] += ' ' + line\n",
        "            else:\n",
        "                current_segment['text'] = line\n",
        "\n",
        "    if current_segment:\n",
        "        segments.append(current_segment)\n",
        "\n",
        "    return segments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Segment 1: Introduction to Photosynthesis\n",
            "Timestamp: 11.2s - 16.9s\n",
            "Analysis:\n",
            "Introduction to Photosynthesis\n",
            "KEY POINTS:\n",
            "* The speaker introduces the topic of photosynthesis in a casual setting\n",
            "* The importance of sunlight and vitamin D is mentioned\n",
            "* The speaker asks the audience if they know about photosynthesis and invites them to learn about it\n",
            "IMPORTANCE: This segment is important for learning because it sets the tone for the rest of the video and grabs the audience's attention. It also establishes the speaker's informal and conversational style, making the topic more approachable and engaging.\n",
            "\n",
            "Questions:\n",
            "Q: What is special about the day mentioned in the video segment?\n",
            "A: It's a lovely sunny day.\n",
            "\n",
            "Q: Why is sunlight important, according to the introduction?\n",
            "A: Sunlight is important, and it also helps our bodies make vitamin D.\n",
            "\n",
            "Q: What is the speaker inviting the audience to do in the video segment?\n",
            "A: The speaker is inviting the audience to learn about photosynthesis.\n",
            "\n",
            "Segment 2: Definition and Explanation of Photosynthesis\n",
            "Timestamp: 22.1s - 29.6s\n",
            "Analysis:\n",
            "Definition and Explanation of Photosynthesis\n",
            "KEY POINTS:\n",
            "* The word \"photosynthesis\" is broken down into its Greek roots: \"photo\" meaning light and \"synthesis\" meaning putting together\n",
            "* The speaker explains that photosynthesis is the process by which plants use sunlight, water, and carbon dioxide to make food\n",
            "* The role of chloroplasts and stomata in photosynthesis is mentioned\n",
            "IMPORTANCE: This segment is important for learning because it provides a clear and concise definition of photosynthesis. By explaining the word's origins and components, the speaker helps the audience understand the concept and its significance.\n",
            "\n",
            "Questions:\n",
            "Here are three quiz questions based on the video segment:\n",
            "\n",
            "Q: What does the word \"photo\" mean in the word \"photosynthesis\"?\n",
            "A: Light\n",
            "\n",
            "Q: What are the three things that plants use to make food through photosynthesis?\n",
            "A: Sunlight, water, and carbon dioxide\n",
            "\n",
            "Q: Where do plants get the sunlight, water, and carbon dioxide they need to make food?\n",
            "A: From the air through stomata and from the sun, water is absorbed by the roots.\n",
            "\n",
            "Segment 3: Plant Respiration and Nutrient Uptake\n",
            "Timestamp: 25.0s - 32.6s\n",
            "Analysis:\n",
            "Plant Respiration and Nutrient Uptake\n",
            "KEY POINTS:\n",
            "* Plants breathe in carbon dioxide and give out oxygen, just like humans\n",
            "* Plants use water and other nutrients to make food, which is absorbed through their roots\n",
            "* The role of chloroplasts in converting sunlight, water, and carbon dioxide into sugar and oxygen is explained\n",
            "IMPORTANCE: This segment is important for learning because it highlights the similarities and differences between plant and human respiration. It also emphasizes the importance of plants in producing oxygen and regulating the atmosphere.\n",
            "\n",
            "Questions:\n",
            "Q: What do plants breathe in to help them make food?\n",
            "A: Carbon dioxide\n",
            "\n",
            "Q: What do plants give out after they breathe in carbon dioxide?\n",
            "A: Oxygen\n",
            "\n",
            "Q: How do plants get the water and nutrients they need to make food?\n",
            "A: Through their roots\n",
            "\n",
            "Segment 4: Chlorophyll and the Importance of Plants\n",
            "Timestamp: 11.2s - 16.9s\n",
            "Analysis:\n",
            "Chlorophyll and the Importance of Plants\n",
            "KEY POINTS:\n",
            "* Chlorophyll is introduced as a green pigment found in chloroplasts that helps plants absorb sunlight\n",
            "* Plants are referred to as the \"lungs of the world\" due to their role in producing oxygen and absorbing carbon dioxide\n",
            "IMPORTANCE: This segment is important for learning because it underscores the vital role of plants in maintaining the Earth's atmosphere and supporting life. By highlighting the unique characteristics of plants, such as chlorophyll, the speaker encourages the audience to appreciate and respect the natural world.\n",
            "\n",
            "Questions:\n",
            "Q: What is special about plants that helps them catch sunlight?\n",
            "A: They have a green pigment called chlorophyll.\n",
            "\n",
            "Q: Why are plants sometimes called the \"lungs of the world\"?\n",
            "A: Because they help make oxygen for us to breathe and absorb bad air.\n",
            "\n",
            "Q: What do plants use to make oxygen for us?\n",
            "A: Sunlight, water, and a bad gas called carbon dioxide.\n"
          ]
        }
      ],
      "source": [
        "# ... existing code ...\n",
        "\n",
        "class EducationalAssistant:\n",
        "    def __init__(self, groq_client):\n",
        "        self.groq_client = groq_client\n",
        "        \n",
        "    def process_youtube_video(self, video_url):\n",
        "        \"\"\"Process a YouTube video and extract captions\"\"\"\n",
        "        yt = YouTube(url=video_url)\n",
        "        segments = None\n",
        "        \n",
        "        # Try auto-generated captions first\n",
        "        if yt.captions and 'a.en' in yt.captions:\n",
        "            caption = yt.captions['a.en']\n",
        "            raw_captions = caption.generate_srt_captions()\n",
        "            segments = _parse_srt_captions(raw_captions)\n",
        "        # Fall back to manual English captions\n",
        "        elif yt.captions and 'en' in yt.captions:\n",
        "            caption = yt.captions['en']\n",
        "            raw_captions = caption.generate_srt_captions()\n",
        "            segments = _parse_srt_captions(raw_captions)\n",
        "            \n",
        "        return segments\n",
        "    \n",
        "    def identify_key_segments_with_llm(self, segments, max_chunk_size=1000):\n",
        "        \"\"\"Use LLM to identify important segments in the video\"\"\"\n",
        "        # Combine all text first\n",
        "        full_text = \" \".join(segment['text'] for segment in segments)\n",
        "        \n",
        "        prompt = \"\"\"Analyze this video transcript and identify the most important segments or topics. \n",
        "        For each important segment, provide:\n",
        "        1. A brief title for the segment\n",
        "        2. The key points or main ideas discussed\n",
        "        3. Why this segment is important for learning\n",
        "        \n",
        "        Format your response as:\n",
        "        SEGMENT: [title]\n",
        "        KEY POINTS: [bullet points of main ideas]\n",
        "        IMPORTANCE: [why this matters]\n",
        "        \n",
        "        Transcript:\n",
        "        {text}\n",
        "        \"\"\"\n",
        "        \n",
        "        completion = self.groq_client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt.format(text=full_text)\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_completion_tokens=1024,\n",
        "            top_p=1,\n",
        "            stream=False,\n",
        "        )\n",
        "        \n",
        "        # Get LLM analysis\n",
        "        analysis = completion.choices[0].message.content\n",
        "        \n",
        "        # Now match the analyzed segments back to timestamps\n",
        "        return self._match_segments_to_timestamps(analysis, segments)\n",
        "    \n",
        "    def _match_segments_to_timestamps(self, analysis, original_segments):\n",
        "        \"\"\"Match the LLM-identified segments with video timestamps\"\"\"\n",
        "        # Split analysis into segments\n",
        "        llm_segments = analysis.split('SEGMENT:')[1:]  # Skip empty first split\n",
        "        \n",
        "        key_segments = []\n",
        "        for llm_segment in llm_segments:\n",
        "            # Extract title and content\n",
        "            lines = llm_segment.strip().split('\\n')\n",
        "            title = lines[0].strip()\n",
        "            \n",
        "            # Find matching content in original segments\n",
        "            for i, segment in enumerate(original_segments):\n",
        "                if any(keyword.lower() in segment['text'].lower() \n",
        "                      for keyword in title.split()):\n",
        "                    # Found a matching segment\n",
        "                    key_segments.append({\n",
        "                        'start': segment['start'],\n",
        "                        'end': segment['end'],\n",
        "                        'title': title,\n",
        "                        'text': segment['text'],\n",
        "                        'analysis': llm_segment.strip()\n",
        "                    })\n",
        "                    break\n",
        "        \n",
        "        return key_segments\n",
        "    \n",
        "    def generate_questions(self, segment, grade, num_questions=3):\n",
        "        \"\"\"Generate questions for a given segment using Groq\"\"\"\n",
        "        prompt = f\"\"\"Based on this video segment titled \"{segment['title']}\", generate {num_questions} quiz questions.\n",
        "        Consider the following analysis of the segment:\n",
        "        {segment['analysis']}\n",
        "        \n",
        "        Generate questions that test understanding of the key concepts for a grade {grade} student.\n",
        "        Format each question as:\n",
        "        Q: [question]\n",
        "        A: [answer]\n",
        "        \n",
        "        Content: {segment['text']}\n",
        "        Generate questions only based on the content of the segment, do not make up any questions.\n",
        "        \"\"\"\n",
        "        \n",
        "        completion = self.groq_client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_completion_tokens=1024,\n",
        "            top_p=1,\n",
        "            stream=False,\n",
        "        )\n",
        "        \n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "# Example usage\n",
        "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
        "assistant = EducationalAssistant(client)\n",
        "\n",
        "# Process video\n",
        "video_url = \"https://www.youtube.com/watch?v=D1Ymc311XS8\"\n",
        "segments = assistant.process_youtube_video(video_url)\n",
        "\n",
        "grade = 2\n",
        "num_questions = 3\n",
        "\n",
        "if segments:\n",
        "    # Get LLM-identified key segments\n",
        "    key_segments = assistant.identify_key_segments_with_llm(segments)\n",
        "    \n",
        "    # Generate questions for each key segment\n",
        "    for i, segment in enumerate(key_segments, 1):\n",
        "        print(f\"\\nSegment {i}: {segment['title']}\")\n",
        "        print(f\"Timestamp: {segment['start']:.1f}s - {segment['end']:.1f}s\")\n",
        "        print(\"Analysis:\")\n",
        "        print(segment['analysis'])\n",
        "        print(\"\\nQuestions:\")\n",
        "        questions = assistant.generate_questions(segment, grade, num_questions)\n",
        "        print(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add these imports at the top\n",
        "!pip install moviepy\n",
        "from moviepy.editor import VideoFileClip\n",
        "import speech_recognition as sr\n",
        "\n",
        "# Add this method to the EducationalAssistant class\n",
        "def process_video_file(self, video_path):\n",
        "    \"\"\"Process a non-YouTube video file\"\"\"\n",
        "    # Extract audio\n",
        "    video = VideoFileClip(video_path)\n",
        "    audio = video.audio\n",
        "    \n",
        "    # Save audio temporarily\n",
        "    audio_path = \"temp_audio.wav\"\n",
        "    audio.write_audiofile(audio_path)\n",
        "    \n",
        "    # Initialize speech recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "    \n",
        "    # Convert audio to text\n",
        "    with sr.AudioFile(audio_path) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        text = recognizer.recognize_google(audio_data)\n",
        "    \n",
        "    # Clean up\n",
        "    os.remove(audio_path)\n",
        "    video.close()\n",
        "    audio.close()\n",
        "    \n",
        "    # Create a single segment with the transcribed text\n",
        "    segment = {\n",
        "        'start': 0,\n",
        "        'end': video.duration,\n",
        "        'text': text\n",
        "    }\n",
        "    \n",
        "    return [segment]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For YouTube videos\n",
        "assistant = EducationalAssistant(groq_client)\n",
        "segments = assistant.process_youtube_video(\"https://youtube.com/watch?v=...\")\n",
        "\n",
        "# For other videos\n",
        "segments = assistant.process_video_file(\"path/to/video.mp4\")\n",
        "\n",
        "# Generate questions\n",
        "key_segments = assistant.identify_key_segments(segments)\n",
        "for segment in key_segments:\n",
        "    questions = assistant.generate_questions(segment['text'])\n",
        "    print(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "audio_path = \"/content/test_audio.mp3\"\n",
        "\n",
        "api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "client = Groq(api_key=api_key)\n",
        "\n",
        "\n",
        "with open(audio_path, \"rb\") as file:\n",
        "    transcription = client.audio.transcriptions.create(\n",
        "      file=(audio_path, file.read()),\n",
        "      model=\"whisper-large-v3\",\n",
        "      response_format=\"verbose_json\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NQu1KO3RMjcO"
      },
      "outputs": [],
      "source": [
        "video_url = \"https://www.youtube.com/watch?v=ZcI2B92JlJU\"\n",
        "yt = YouTube(url=video_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XMM6IPduMmIY"
      },
      "outputs": [],
      "source": [
        "if yt.captions and 'a.en' in yt.captions:\n",
        "    caption = yt.captions['a.en']\n",
        "    raw_captions = caption.generate_srt_captions()\n",
        "    segments = _parse_srt_captions(raw_captions)\n",
        "\n",
        "# Fall back to manual English captions\n",
        "if yt.captions and 'en' in yt.captions:\n",
        "    caption = yt.captions['en']\n",
        "    raw_captions = caption.generate_srt_captions()\n",
        "    segments = _parse_srt_captions(raw_captions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXvb0BuOMnu2"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq()\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_completion_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
